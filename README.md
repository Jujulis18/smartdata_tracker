# SmartData Tracker

## Objectif du Projet

SmartData Tracker vise √† automatiser le processus de veille sur des sites web, en extrayant des articles et en les organisant par cat√©gories. Cela permet aux entreprises de rester inform√©es des derni√®res tendances et d√©veloppements dans leur domaine, sans avoir √† consacrer du temps √† la recherche manuelle.

## Valeur Ajout√©e

- **Automatisation du Processus de Veille** : Gain de temps en √©vitant la recherche manuelle d'articles et efficacit√© accrue en parcourant et extrayant des articles de multiples sites web en un temps record.
- **Organisation et Gestion des Articles** : Cat√©gorisation des articles pour une meilleure gestion et recherche d'informations, et filtrage des articles par cat√©gories pour une recherche d'informations plus efficace.
- **Visualisation et Export des Donn√©es** : Visualisation interactive des articles pour une analyse et une prise de d√©cision facilit√©e, et export des donn√©es en CSV et Excel pour une analyse ult√©rieure et la cr√©ation de rapports.
- **Scalabilit√© et Maintenabilit√©** : Con√ßu pour √™tre scalable, capable de g√©rer un grand nombre de sites web et d'articles sans perte de performance, avec une architecture modulaire facilitant la maintenance et les mises √† jour.

## Table des Mati√®res

- [Fonctionnalit√©s](#fonctionnalit√©s)
- [Architecture du Projet](#architecture-du-projet)

## Fonctionnalit√©s

- Extraction automatique des articles √† partir de sites web.
- Interface utilisateur interactive pour visualiser et filtrer les articles.
- Export des donn√©es en CSV et Excel pour une analyse ult√©rieure.
- Organisation des articles par cat√©gories pour une meilleure gestion.

[Interface Streamlit](https://smartdatatracker-jvmys59gtfqwup9eetytlt.streamlit.app/)
(Probl√®me de d√©pendance, veillez suivre le guide de d√©marrage)

<img src="https://github.com/user-attachments/assets/c3bf4b60-1183-41f2-b435-19caeee35b6e" width=50% height=50%>




## Architecture du Projet

<img src="https://github.com/user-attachments/assets/c2bb2252-e1b8-4a67-9715-d7d7dfc52fe2" width=45% height=50%>

### √âtape 1: S√©lection du Site et Configuration des Locateurs

- **S√©lection du site** : S√©lectionner le site √† scraper
- **Agent LeChat** : Cet agent va parcourir la page pour d√©terminer les locateurs utiles.
  - **Locateurs √† r√©cup√©rer** :
    - Titre
    - R√©sum√©
    - Lien
    - Date (optionnelle)
    - Bouton "Next" ou "Previous"
  - **Configuration Output Format** :
    ```json
    {
      "url": "URL du site",
      "locatorTitle": "Locateur pour le titre",
      "locatorDescription": "Locateur pour le r√©sum√©",
      "locatorDate": "Locateur pour la date",
      "locatorLink": "Locateur pour le lien",
      "locatorNextPage": "Locateur pour le bouton Next/Previous",
      "category": "Cat√©gorie du site"
    }
    ```

### √âtape 2: Script Python pour It√©rer sur les Pages

- **Script Python** : Ce script va utiliser les locateurs pour r√©cup√©rer les articles.
  - **Fonctionnalit√©s** :
    - It√©rer sur les pages
    - R√©cup√©rer les articles avec leurs informations
    - √ätre g√©n√©rique pour utiliser des locateurs bas√©s sur des ID ou des classes
  - **Output Format** :
    ```csv
    id, title, description, link, date, category
    ```

### √âtape 3: Sauvegarder les Informations dans un Excel

- **Sauvegarde** : Les informations r√©cup√©r√©es seront sauvegard√©es dans un fichier Excel.
- **Version actuelle** : export en format csv

### √âtape 4: Ajout de Tags aux Cat√©gories (TO DO)

- **Agent LeChat** : L'agent va d√©terminer et ajouter des tags √† la colonne "category" pour sp√©cifier le th√®me.
  - **Liste des Th√®mes** : Une liste des th√®mes sera enrichie au fur et √† mesure pour utiliser le m√™me vocabulaire et mieux organiser les donn√©es.
  - **Theme Format** :
    ```csv
    tags, main_category, date
    ```

### √âtape 5: Extraction des Nouveaux Articles (TO DO)

- **Script Python** : Ce script va extraire les nouveaux articles sur une p√©riode donn√©e (semaine ou mois).
  - **Input** : M√™me configuration que pr√©c√©dementt
  - **Fonctionnalit√©s** :
    - Si pas de locator date, √©tape suppl√©mentaire pour trouver la date dans l'article
  - **Output Format** : M√™me format csv
  - **Sauvegarde** : Possibilit√© de sauvegarder sur Excel

### √âtape 6: Interfaces Utilisateur

- **Interface d'Extraction** :
  - Un formulaire pour entrer l'URL.
  - Un bouton pour lancer l'extraction.
  - Un aper√ßu des donn√©es avant la sauvegarde.

- **Interface de Visualisation** (TO DO):
  - Une table pour afficher les articles avec des filtres multiples par cat√©gories.
  - Des boutons pour des actions rapides (par exemple, sauvegarde sur Excel).

---

## üöÄ Comment d√©marrer

1. Clonez le d√©p√¥t :  

2. Installez les d√©pendances :  
```bash
pip install -r requirements.txt
```
3. Lancez le dashboard :

```bash
streamlit run app.py
```

---
